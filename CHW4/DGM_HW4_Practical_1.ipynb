{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaR4bCe5beAA"
      },
      "source": [
        "<font face=\"Times New Roman\" size=5>\n",
        "<div dir=rtl align=\"center\">\n",
        "<font face=\"Times New Roman\" size=5>\n",
        "In The Name of God\n",
        "</font>\n",
        "<br>\n",
        "<img src=\"https://logoyar.com/content/wp-content/uploads/2021/04/sharif-university-logo.png\" alt=\"University Logo\" width=\"150\" height=\"150\">\n",
        "<br>\n",
        "<font face=\"Times New Roman\" size=4 align=center>\n",
        "Sharif University of Technology - Department of Electrical Engineering\n",
        "</font>\n",
        "<br>\n",
        "<font color=\"#008080\" size=6>\n",
        "Deep Generative Models\n",
        "</font>\n",
        "\n",
        "<hr/>\n",
        "<font color=\"#800080\" size=5>\n",
        "Assignment 4: Energy-based Models\n",
        "<br>\n",
        "</font>\n",
        "<font size=5>\n",
        "Instructor: Dr. S. Amini\n",
        "<br>\n",
        "</font>\n",
        "<font size=4>\n",
        "Fall 2024\n",
        "<br>\n",
        "</font>\n",
        "<font face=\"Times New Roman\" size=4>\n",
        "Deadline: Month day at 23:55\n",
        "</font>\n",
        "<hr>\n",
        "</div></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLeVLaOjmdAn"
      },
      "source": [
        "This homework helps you implement a Energy-based Model (EBM).  \n",
        "For references please refer to the original [Implicit Generation and Generalization in Energy-Based Models](https://arxiv.org/abs/1903.08689).\n",
        "\n",
        "In this homework you need to complete the notebook and run all the cells.\n",
        "We have specified the parts to be completed with `TODO` tags inside the code blocks.\n",
        "\n",
        "**NOTES**:\n",
        "* Feel free to change any part of notebook, but remeber to use comments for clarification.\n",
        "* You can get **complete score** for this notebook if your codes work properly and without errors.\n",
        "* This notebook is tested with *Google Colab*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3cq7tazxbeAF"
      },
      "outputs": [],
      "source": [
        "name = \"AmirHossein Naghdi\"\n",
        "studentId = \"400102169\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1OtqJ4Sniak"
      },
      "source": [
        "# Energy-based Models (EBMs) (80 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du7Y-Baxn-xN"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHBmIDAen_jf"
      },
      "source": [
        "In this notebook, we will look at energy-based deep learning models, and focus on their application as generative models.\n",
        "\n",
        "First, let's import our libraries below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibCHvW_xFxAY",
        "outputId": "c2afa81a-db3f-4fce-9c72-4e907a29d56c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Standard libraries\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "## PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Torchvision\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGoeApIVobpz"
      },
      "source": [
        "## Energy Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zuuiSOeof63"
      },
      "source": [
        "As we have seen in the class, Energy-based models tend to predict probability density distribution. For this purpose we need to learn given probability:\n",
        "\n",
        "\n",
        "\n",
        "$p_{\\theta }( x_{train}) =\\frac{e^{f_{\\theta }( x)}}{Z( \\theta )}$\n",
        "\n",
        "\n",
        "\n",
        "Here $p_{\\theta }( x_{train})$ stands for probability density of our training data distribution. We know that calculating the partition function ($Z( \\theta )$) is interactable. For this purpose we will use contrastive divergence algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJPqyLVAs0bO"
      },
      "source": [
        "### Contrastive Divergence\n",
        "\n",
        "We train generative models usually by maximum likelihood estimation. But the exact likelihood of a point cannot be determined due to intractable normalization constant $Z(\\theta)$, we need to train energy-based models slightly different. We can re-write our maximum likelihood objective where we maximize the probability of $\\mathbf{x}_{\\text{train}}$ compared to a randomly sampled data point of our model:\n",
        "\n",
        "$$\n",
        "\\begin{split}\n",
        "    \\nabla_{\\theta}\\mathcal{L}_{\\text{MLE}}(\\mathbf{\\theta}) & = \\nabla_{\\theta}\\log p_{\\theta}(\\mathbf{x})\\\\[5pt]\n",
        "    & \\approx  \\nabla_{\\theta}F_{\\theta}(\\mathbf{x_{\\text{train}}}) - \\nabla_{\\theta}F_{\\theta}(\\mathbf{x_{\\text{sample}}})\n",
        "\\end{split}\n",
        "$$\n",
        "\n",
        "Note that the loss is still an objective we want to minimize. Thus, we try to minimize the energy for data points from the dataset, while maximizing the energy for randomly sampled data points from our model. The trick for sampling is that we approximate $Z(\\theta)$ by a single Monte-Carlo sample. This gives us the exact same objective as written above.\n",
        "\n",
        "Visually, the objective is shown below (figure - [Stefano Ermon and Aditya Grover](https://deepgenerativemodels.github.io/assets/slides/cs236_lecture11.pdf)):\n",
        "\n",
        "\n",
        "<center width=\"100%\"><img src=\"https://uvadlc-notebooks.readthedocs.io/en/latest/_images/contrastive_divergence.svg\" width=\"90%\"></center>\n",
        "\n",
        "\n",
        "The point on the right, called \"correct answer\", represents a data point from the dataset (i.e. $x_{\\text{train}}$), and the left point, \"wrong answer\", a sample from our model (i.e. $x_{\\text{sample}}$). Thus, we try to \"pull up\" the probability of the data points in the dataset, while \"pushing down\" randomly sampled points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTyS6sxkxP31"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "First, we load the MNIST dataset below. Note that we need to normalize the images between -1 and 1 instead of mean 0 and std 1 because during sampling, we have to limit the input space. Scaling between -1 and 1 makes it easier to implement it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "W4k9hWDluSnj"
      },
      "outputs": [],
      "source": [
        "############ TODO #############:\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors with values in [0, 1]\n",
        "    transforms.Normalize((0.,), (1.,))  # Normalize to mean=0., std=1. to scale to [-1, 1]\n",
        "])\n",
        "###############################\n",
        "\n",
        "train_set = MNIST(root='./', train=True, transform=transform, download=True)\n",
        "test_set = MNIST(root='./', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True,  drop_last=True, pin_memory=True)\n",
        "test_loader  = DataLoader(test_set,  batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOqx1hQTxjL7"
      },
      "source": [
        "### CNN Model\n",
        "\n",
        "First, we implement our CNN model. The MNIST images are 28x28, hence a small model is enough. But you are free to use pre-trained Convolution Networks (such as Resnet, etc.)\n",
        "\n",
        "Here we use a smooth activation function like Swish instead of ReLU in the energy model. This is because gradients should not be sparse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SsURXgNLM-gq"
      },
      "outputs": [],
      "source": [
        "class Swish(nn.Module):\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_features=32, out_dim=1):\n",
        "        super(CNNModel, self).__init__()\n",
        "        ############ TODO #############:\n",
        "        # Define hidden layers (Conv) in and out dimensions\n",
        "        hidden_dim1 = hidden_features // 2\n",
        "        hidden_dim2 = hidden_features\n",
        "        hidden_dim3 = hidden_features * 2\n",
        "        ################################\n",
        "\n",
        "        # Series of convolutions and Swish activation functions\n",
        "        # your're free to implement any CNN Network. You can also use pretrained networks (like ResNet, etc.) instead.\n",
        "        ############ TODO #############:\n",
        "        self.cnn_net = nn.Sequential(\n",
        "                nn.Conv2d(1, hidden_dim1, kernel_size=5, stride=2, padding=4), # [16x16] - Larger padding to get 32x32 image\n",
        "                Swish(),\n",
        "                nn.Conv2d(hidden_dim1, hidden_dim2, kernel_size=3, stride=2, padding=1), #  [8x8]\n",
        "                Swish(),\n",
        "                nn.Conv2d(hidden_dim2, hidden_dim3, kernel_size=3, stride=2, padding=1), # [4x4]\n",
        "                Swish(),\n",
        "                nn.Conv2d(hidden_dim3, hidden_dim3, kernel_size=3, stride=2, padding=1), # [2x2]\n",
        "                Swish(),\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(hidden_dim3*4, hidden_dim3),\n",
        "                Swish(),\n",
        "                nn.Linear(hidden_dim3, out_dim)\n",
        "        )\n",
        "        ################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Feed the input to the network and return the output\n",
        "        ############ TODO #############:\n",
        "        # Feed the input through the convolutional network\n",
        "        x = self.cnn_net(x).squeeze(dim=-1)\n",
        "        return x\n",
        "        ################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Npjk5kVwxy94"
      },
      "source": [
        "### Sampling buffer\n",
        "\n",
        "In this part, we construct our sampler. To use the contrastive divergence objective, we need to generate samples during training. The simple way to sampling is to use simple MCMC algorithm, but in practice it costs too much. So here we use *Langevin MCMC* that uses gradient for better sampling.\n",
        "\n",
        "<center width=\"100%\"><img src=\"https://uvadlc-notebooks.readthedocs.io/en/latest/_images/sampling.svg\" width=\"90%\"></center>\n",
        "\n",
        "Below, we implement the sampling class. The function `sample_new_exmps` returns a new batch of \"fake\" images . These images are generated using MCMC. For more efficiency, each time we only generate 5% of sample size and other 95% are randomly picked from our buffer. We perform MCMC for 80 iterations to improve the image quality and come closer to samples from $p_{\\theta}(\\mathbf{x})$. In the function `generate_samples`, we implemented the MCMC for images. Note that the hyperparameters in this code are for MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cxaaO617W5Wp"
      },
      "outputs": [],
      "source": [
        "class Sampler:\n",
        "\n",
        "    def __init__(self, model, img_shape, sample_size, max_len=8192):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            model - Neural network to use for modeling E_theta\n",
        "            img_shape - Shape of the images to model\n",
        "            sample_size - Batch size of the samples\n",
        "            max_len - Maximum number of data points to keep in the buffer\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.img_shape = img_shape\n",
        "        self.sample_size = sample_size\n",
        "        self.max_len = max_len\n",
        "        self.examples = [(torch.rand((1,) + img_shape) * 2 - 1) for _ in range(self.sample_size)]\n",
        "\n",
        "    def sample_new_exmps(self, steps=60, step_size=10):\n",
        "        \"\"\"\n",
        "        Function for getting a new batch of \"fake\" images.\n",
        "        Inputs:\n",
        "            steps - Number of iterations in the MCMC algorithm\n",
        "            step_size - Learning rate nu in the algorithm above\n",
        "        \"\"\"\n",
        "        # Choose 95% of the batch from the buffer, 5% generate from scratch\n",
        "        # Only generate 5% of sample size and use other 95% from buffer (examples)\n",
        "        # You can generate samples the same way they're generated in \"examples\"\n",
        "        # Then randomly choose 95% of sample size from examples and add newly generated one to it\n",
        "        ############ TODO #############:\n",
        "        # Generate 5% new samples\n",
        "        # Choose 95% of the batch from the buffer, 5% generate from scratch\n",
        "        n_new = np.random.binomial(self.sample_size, 0.05)\n",
        "        rand_imgs = torch.rand((n_new,) + self.img_shape) * 2 - 1\n",
        "        old_imgs = torch.cat(random.choices(self.examples, k=self.sample_size-n_new), dim=0)\n",
        "        inp_imgs = torch.cat([rand_imgs, old_imgs], dim=0).detach().to(device)\n",
        "        ################################\n",
        "\n",
        "        # Perform MCMC sampling\n",
        "        inp_imgs = Sampler.generate_samples(self.model, inp_imgs, steps=steps, step_size=step_size)\n",
        "\n",
        "        # Add new images to the buffer and remove old ones if needed\n",
        "        self.examples = list(inp_imgs.to(torch.device(\"cpu\")).chunk(self.sample_size, dim=0)) + self.examples\n",
        "        self.examples = self.examples[:self.max_len]\n",
        "        return inp_imgs\n",
        "\n",
        "    @staticmethod\n",
        "    def generate_samples(model, newly_imgs, steps=60, step_size=10, return_img_per_step=False):\n",
        "        \"\"\"\n",
        "        Function for sampling images for a given model.\n",
        "        Inputs:\n",
        "            model - Neural network to use for modeling E_theta\n",
        "            newly_imgs - Images to start from for sampling. If you want to generate new images.\n",
        "            steps - Number of iterations in the Langevin MCMC algorithm.\n",
        "            step_size - Learning rate nu in the algorithm above\n",
        "            return_img_per_step - If True, we return the sample at every iteration of the MCMC\n",
        "        \"\"\"\n",
        "        # Before MCMC: set model parameters to \"required_grad=False\"\n",
        "        # because we are only interested in the gradients of the input.\n",
        "        is_training = model.training\n",
        "        model.eval()\n",
        "        for p in model.parameters():\n",
        "            p.requires_grad = False\n",
        "        newly_imgs.requires_grad = True\n",
        "\n",
        "        # Enable gradient calculation if not already the case\n",
        "        had_gradients_enabled = torch.is_grad_enabled()\n",
        "        torch.set_grad_enabled(True)\n",
        "\n",
        "        # we use a buffer tensor in which we generate noise each loop iteration.\n",
        "        # more efficient than creating a new tensor every iteration.\n",
        "        # generate random tensor using image shape\n",
        "        ############ TODO #############:\n",
        "        # print(f'{newly_imgs.shape=}')\n",
        "        noise = torch.randn(newly_imgs.shape, device=newly_imgs.device)\n",
        "        ################################\n",
        "\n",
        "        # List for storing generations at each step (for later analysis)\n",
        "        imgs_per_step = []\n",
        "\n",
        "        # Loop over K (steps)\n",
        "        for _ in range(steps):\n",
        "            # You can use tensor functions to complete the code. eg. tensor.add, tensor.grad\n",
        "\n",
        "            # Part 1:\n",
        "            # Sample noise tensor data from a normal dist (mu=0, std=0.005).\n",
        "            # Add the noise to the new image\n",
        "            # Clamp it between -1 and 1\n",
        "            ############ TODO #############:\n",
        "            noise.normal_(0, 0.005)\n",
        "            newly_imgs.data.add_(noise.data)\n",
        "            newly_imgs.data.clamp_(min=-1.0, max=1.0)\n",
        "            ################################\n",
        "\n",
        "            # Part 2:\n",
        "            # Feed new image to the model (**model output sign is important)\n",
        "            # Use backward on sum of output to calculate gradient\n",
        "            # Clamp tensor gradient between -0.05 and 0.05 (preventing too high gradients)\n",
        "            ############ TODO #############:\n",
        "            output = -model(newly_imgs)\n",
        "            output.sum().backward()\n",
        "            newly_imgs.grad.data.clamp_(-0.03, 0.03) # For stabilizing and preventing too high gradients\n",
        "            ################################\n",
        "\n",
        "            # Part 3:\n",
        "            # Add grad to the image with step_size (like the given algorithm)\n",
        "            ############ TODO #############:\n",
        "            newly_imgs.data.add_(-step_size * newly_imgs.grad.data)\n",
        "            ################################\n",
        "\n",
        "            newly_imgs.grad.detach_()\n",
        "            newly_imgs.grad.zero_()\n",
        "            newly_imgs.data.clamp_(min=-1.0, max=1.0)\n",
        "\n",
        "            if return_img_per_step:\n",
        "                imgs_per_step.append(newly_imgs.clone().detach())\n",
        "\n",
        "        # Reactivate gradients for parameters for training\n",
        "        for p in model.parameters():\n",
        "            p.requires_grad = True\n",
        "        model.train(is_training)\n",
        "\n",
        "        # Reset gradient calculation to setting before this function\n",
        "        torch.set_grad_enabled(had_gradients_enabled)\n",
        "\n",
        "        if return_img_per_step:\n",
        "            return torch.stack(imgs_per_step, dim=0)\n",
        "        else:\n",
        "            return newly_imgs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSLSbpj5z94m"
      },
      "source": [
        "### Training algorithm\n",
        "\n",
        "Below is shown a summary of the full training algorithm of an energy model:\n",
        "\n",
        "<center width=\"100%\"><img src=\"https://uvadlc-notebooks.readthedocs.io/en/latest/_images/training_algorithm.svg\" width=\"80%\"></center>\n",
        "\n",
        "Given algorithm, for each batch of data we're going to, first, add a small noise to image, then we sample a fake image using `sample_new_example`. After this we feed these images to our `Model`. At the end we use our `ebm_loss` to calculate loss and backward to complete our trainig.\n",
        "\n",
        "For evaluation we use almost the same structure as our training, but with a different loss.\n",
        "\n",
        "After training phase we're going to use `generate_image` to sample from our model (generate images)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "igfcMKn6fcsx"
      },
      "outputs": [],
      "source": [
        "# Implement the given algorithm\n",
        "# In order to complete code you have to add the small noise to image\n",
        "# Sample a fake image\n",
        "# Feed both real image and fake image to the network\n",
        "# And use the ebm loss\n",
        "############ TODO #############:\n",
        "def train_one_epoch(model, train_loader, optimizer, sampler, alpha):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        model: implemented CNN\n",
        "        train_loader: train Dataloader\n",
        "        optimizer: Optimizer to optimize model\n",
        "        sampler: Sampler to generate samples\n",
        "        alpha: hyperparameter for loss\n",
        "    Returns:\n",
        "        float: Epoch loss\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_loss_cd = 0\n",
        "    total_loss_rg = 0\n",
        "\n",
        "    for img, _ in train_loader:\n",
        "        img = img.to(device)\n",
        "        small_noise = torch.randn_like(img) * 0.005\n",
        "        img.add_(small_noise).clamp_(min=-1.0, max=1.0)\n",
        "\n",
        "        # Generate fake images using the sampler\n",
        "        fake_imgs = sampler.sample_new_exmps(steps=60, step_size=10)\n",
        "\n",
        "        # Feed both real and fake images to the model\n",
        "        # print(f'{img.shape=}')\n",
        "        # print(f'{fake_imgs.shape=}')\n",
        "        real_out = model(img)\n",
        "        fake_out = model(fake_imgs)\n",
        "\n",
        "        # Compute the contrastive divergence loss: E(G(z)) - E(x)\n",
        "        loss_cd = fake_out.mean() - real_out.mean()\n",
        "        total_loss_cd += loss_cd.item()\n",
        "\n",
        "        # Compute the regularization loss: E(x)^2 + E(G(z))^2\n",
        "        loss_rg = (real_out ** 2 + fake_out ** 2).mean()\n",
        "        total_loss_rg += loss_rg.item()\n",
        "\n",
        "        loss = loss_cd + alpha * loss_rg\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    mean_loss = total_loss / len(train_loader)\n",
        "    mean_loss_cd = total_loss_cd / len(train_loader)\n",
        "    mean_loss_rg = total_loss_rg / len(train_loader)\n",
        "\n",
        "    return mean_loss, mean_loss_cd, mean_loss_rg\n",
        "################################\n",
        "\n",
        "def test_one_epoch(model, test_loader):\n",
        "    # For validating, we use the contrastive divergence between purely random images and unseen examples\n",
        "    total_cdiv = 0\n",
        "\n",
        "    for imgs, _ in train_loader:\n",
        "        imgs = imgs.to(device)\n",
        "        fake_imgs = torch.rand_like(imgs) * 2 - 1\n",
        "\n",
        "        real_out = model(imgs)\n",
        "        fake_out = model(fake_imgs)\n",
        "\n",
        "        cdiv = fake_out.mean() - real_out.mean()\n",
        "        total_cdiv += cdiv.item()\n",
        "\n",
        "    return total_cdiv / len(test_loader)\n",
        "\n",
        "# Implement sample generator\n",
        "# Create a random noise using image shape and sample size\n",
        "# Use generate_samples to get samples\n",
        "############ TODO #############:\n",
        "def generate_image(model, sample_size, steps=256, step_size=16):\n",
        "    model.eval()\n",
        "    start_imgs = torch.randn((sample_size,) + img_shape).to(device)  # Start with random noise\n",
        "    start_imgs = start_imgs * 2 - 1  # Scale noise to [-1, 1]\n",
        "    torch.set_grad_enabled(True)  # Tracking gradients for sampling necessary\n",
        "    imgs_per_step = Sampler.generate_samples(model, start_imgs, steps=steps, step_size=step_size, return_img_per_step=True)\n",
        "    torch.set_grad_enabled(False)\n",
        "    return imgs_per_step\n",
        "################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31y_cfcQ2HIT"
      },
      "source": [
        "### Loss\n",
        "\n",
        "Here we define our Energy-based Model loss. EBM loss consist of two different losses.\n",
        "\n",
        "\n",
        "1.   Contrastive divergence using our energy model $f_{\\theta}$\n",
        "2.   Regularization term is additional training trick to ensure that the output values are in a reasonable range. Without this regularization loss, the output values will fluctuate in a very large range\n",
        "\n",
        "`alpha` is a hyperparameter for regularization term ($\\alpha<1$)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wRdi2N92gO8k"
      },
      "outputs": [],
      "source": [
        "# Implement the given EBM loss\n",
        "############ TODO #############:\n",
        "def ebm_loss(real, fake, alpha):\n",
        "    loss_cd = real.mean() - fake.mean()\n",
        "    loss_rg = (fake.mean() ** 2)\n",
        "    loss = loss_cd + loss_rg * alpha\n",
        "    return loss\n",
        "################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnvmOWcV27zS"
      },
      "source": [
        "### Instantiation\n",
        "\n",
        "Instantiat your **Model**, **Sampler** and **Optimizer**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EnRpbTiibanv"
      },
      "outputs": [],
      "source": [
        "lr = 1e-4\n",
        "alpha = 0.1\n",
        "img_shape = (1, 28, 28)\n",
        "\n",
        "model = CNNModel().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "sampler = Sampler(model, img_shape, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mfmi6-_y3Xdv"
      },
      "source": [
        "### Train Loop\n",
        "\n",
        "Train your model and print loss for each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2TpMlFaxJYS",
        "outputId": "7d6746ae-bd98-4e38-c92f-e4c9d3559d09"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train Loss = (-0.0009895012170337467, -0.0010154986055164073, 0.000259973886574253)\n",
            "Epoch 2: Train Loss = (-2.3348821038587284e-05, -3.0398695741041106e-05, 7.049875031017277e-05)\n"
          ]
        }
      ],
      "source": [
        "train_loss = []\n",
        "epoch = 30\n",
        "for i in range(epoch):\n",
        "  train_loss.append(train_one_epoch(model, train_loader, optimizer, sampler, alpha))\n",
        "  print(f'Epoch {i+1}: Train Loss = {train_loss[-1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U26MoRnm3fpF"
      },
      "source": [
        "### Test\n",
        "Test your Model using Test Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbQgwh_XD2_g"
      },
      "outputs": [],
      "source": [
        "test_one_epoch(model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCYvcxx331Tv"
      },
      "source": [
        "### Generate Image\n",
        "\n",
        "Here you have to use `generate_image` to sample from model and visualize it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzTSKxMuKKDx"
      },
      "outputs": [],
      "source": [
        "############ TODO #############:\n",
        "images_per_step = generate_image(model, sample_size=4, step_size=12)\n",
        "images_per_step = images_per_step.cpu()\n",
        "################################\n",
        "\n",
        "for i in range(images_per_step.shape[1]):\n",
        "    imgs_to_plot = images_per_step[0:256:32,i]\n",
        "    grid = torchvision.utils.make_grid(imgs_to_plot, nrow=imgs_to_plot.shape[0], normalize=True, pad_value=0.5, padding=2)\n",
        "    grid = grid.permute(1, 2, 0)\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.imshow(grid.clone().cpu())\n",
        "    plt.xlabel(\"Generation iteration\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL88lbccbeAL"
      },
      "source": [
        "# Evaluation (20 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RliglE2RbeAL"
      },
      "source": [
        "Now lets evaluate the model more precisely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K1J3M5UnbeAL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.spatial import cKDTree\n",
        "\n",
        "def compute_identifiability(orig_data, synth_data):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        orig_data: original data\n",
        "        synth_data: synthetically generated data\n",
        "\n",
        "    Returns:\n",
        "        identifiability_value: Identifiability value\n",
        "    \"\"\"\n",
        "    def compute_entropy(labels):\n",
        "        \"\"\"\n",
        "        Compute entropy of the given labels.\n",
        "\n",
        "        Args:\n",
        "            labels: input labels\n",
        "\n",
        "        Returns:\n",
        "            entropy: computed entropy\n",
        "        \"\"\"\n",
        "        values, counts = np.unique(labels, return_counts=True)\n",
        "        probabilities = counts / counts.sum()\n",
        "        entropy = -np.sum(probabilities * np.log2(probabilities + 1e-16))\n",
        "        return entropy\n",
        "\n",
        "    orig_data = np.asarray(orig_data)\n",
        "    synth_data = np.asarray(synth_data)\n",
        "\n",
        "    no, x_dim = np.shape(orig_data)\n",
        "\n",
        "    W = np.zeros([x_dim,])\n",
        "\n",
        "    # Compute weights using entropy of each dimension\n",
        "    for i in range(x_dim):\n",
        "        W[i] = compute_entropy(orig_data[:, i])\n",
        "\n",
        "    # Normalize original and synthetic data\n",
        "    orig_data_hat = orig_data / (W + 1e-16)\n",
        "    synth_data_hat = synth_data / (W + 1e-16)\n",
        "\n",
        "    eps = 1e-16  # Small epsilon to avoid division by zero.\n",
        "\n",
        "    # Compute the distances to the two nearest neighbors for each data point in the original data\n",
        "    orig_tree = cKDTree(orig_data_hat)\n",
        "    d_orig, idx_orig = orig_tree.query(orig_data_hat, k=3)\n",
        "\n",
        "    # Compute the distances from each point in the original data to its nearest neighbor in the synthetic data\n",
        "    synth_tree = cKDTree(synth_data_hat)\n",
        "    d_synth, idx_synth = synth_tree.query(orig_data_hat, k=1)\n",
        "\n",
        "    # Compute the identifiability metric\n",
        "    '''\n",
        "    Calculate the difference between the nearest synthetic neighbor distance and\n",
        "    the second nearest original neighbor distance for each data point and\n",
        "    count how many times this difference is negative.\n",
        "    Compute the identifiability value as the fraction of times this occurs.\n",
        "    '''\n",
        "    second_nearest_orig_distances = d_orig[:, 2]\n",
        "    nearest_synth_distances = d_synth\n",
        "\n",
        "    negative_differences = (nearest_synth_distances - second_nearest_orig_distances) < 0\n",
        "    identifiability_value = np.mean(negative_differences)\n",
        "\n",
        "    return identifiability_value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39ob9jXqbeAM"
      },
      "outputs": [],
      "source": [
        "origin_data = []\n",
        "for img, _ in test_loader:\n",
        "    origin_data.append(img.numpy())\n",
        "\n",
        "origin_data = np.concatenate(origin_data, axis=0)\n",
        "\n",
        "origin_data = origin_data.reshape(-1, 28*28)\n",
        "\n",
        "synth_data = []\n",
        "for _ in range(len(test_loader)):\n",
        "    img = generate_image(model, BATCH_SIZE).squeeze().cpu().numpy()\n",
        "    synth_data.append(img)\n",
        "\n",
        "synth_data = np.concatenate(synth_data, axis=0)\n",
        "\n",
        "synth_data = synth_data.reshape(-1, 28*28)\n",
        "\n",
        "\n",
        "identifiability_value = compute_identifiability(origin_data, synth_data)\n",
        "print(identifiability_value)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}